## 知识点

### HashSet与HashMap设计

首先设计一个考虑HashSet，主要考虑如下问题：

**哈希函数**：能够将集合中任意可能的元素映射到一个固定范围的整数值，并将该元素存储到整数值对应的地址上。

**冲突处理**：由于不同元素可能映射到相同的整数值，因此需要在整数值出现「冲突」时，需要进行冲突处理。总的来说，有以下几种策略解决冲突：

- 链地址法：为每个哈希值维护一个链表，并将具有相同哈希值的元素都放入这一链表当中。

![](assets/04哈希表/链地址法.png)

- 开放地址法：当发现哈希值 $h$ 处产生冲突时，根据某种策略，从 $h$ 出发找到下一个不冲突的位置。例如，一种最简单的策略是，不断地检查 $h+1,h+2,h+3,…$ 这些整数对应的位置。
- 再哈希法：当发现哈希冲突后，使用另一个哈希函数产生一个新的地址。

这里以取整函数作为哈希函数，并使用链地址法来实现一个简易的HashSet：

```java
class MyHashSet {
    private static final int BASE = 769;
    private LinkedList<Integer>[] data;

    /**
     * 初始化
     */
    public MyHashSet() {
        data = new LinkedList[BASE];
        for (int i = 0; i < BASE; ++i) {
            data[i] = new LinkedList<>();
        }
    }

    public void add(int key) {
        int h = hash(key);
        for (Integer element : data[h]) {
            if (element == key) {
                return;
            }
        }
        data[h].offerLast(key);
    }

    public void remove(int key) {
        int h = hash(key);
        for (Integer element : data[h]) {
            if (element == key) {
                data[h].remove(element);
                return;
            }
        }
    }

    /**
     * 如果存在key，则返回true
     */
    public boolean contains(int key) {
        int h = hash(key);
        for (Integer element : data[h]) {
            if (element == key) {
                return true;
            }
        }
        return false;
    }

    private int hash(int key) {
        return key % BASE;
    }
}
```

- 时间复杂度：$O(\frac{n}{b})$ 其中 $n$ 是元素个数， $b$ 是链表节点个数
- 空间复杂度：$O(n+b)$

可以考虑从如下方向来优化这个HashSet：
1. 采用更优的哈希函数，比如java8中默认的扰动函数
2. 将链地址法中的链表改为树，比如java8中如果链表长度大于8，将会转为红黑树来存储
3. 扩容策略，当元素个数变大，冲突会显著增加，这时为了提升效率可以进行扩容，比如java8会将容量增加1倍

```
思考：为什么哈希函数在取整操作时，需要选择一个质数呢？

在初等数学中有一个基本定理，任意一个大于1的自然数，要么本身就是质数，要么可以分解为几个质数之积，这种分解本身，具有唯一性。
数字的因子越多，取模后冲突的可能性就越大。而素数的因子恰好只有1和其本身,就非常适合用于解决冲突。
比如2,4,6,8,10,12这6个数：
如果对6取余，得到2,4,0,2,4,0只会得到3种HASH值，6的因子有1,2,3,6。冲突会很多；
如果对7取余，得到2,4,6,1,3,5得到6种HASH值，而7的因子只有1,7。
（即使1的因子最小，但是在实际中并不用，因为mod1相当于不解决冲突。而初始化的的数组就会非常大。）
Hash的用途很多，我们在使用Ngnix做负载均衡的时候，同样用的也是Hash的方式。总的来说，要是数据分布均匀一些，在这种时候就可以考虑使用Hash的方式对数据进行处理。

但凡事都有利弊，对于取整操作选择一个质数，虽然降低了取模时冲突的可能性，但Java8官方并没有使用质数，而是将默认值设置为16，并且扩容之后，依然是2的幂，这是为什么呢？主要有两点好处：
1）计算hash值时，使用2的幂，可以直接通过取低位的固定位数的操作来计算，速度更快。
比如计算26mod16，直接取11010(26)的后4位，1010(10)即为所得。
2）在扩容时，需要对所有元素进行重新哈希，使用2的幂，可以使得一部分元素（均匀分布下是一半的元素），不需要移动。
比如，1010(10)在数组长度为16时，取1010(10)的后4位，得到1010(10)，而在扩容后，长度变为32时，应取1010(10)的后5位，仍然得到1010(10)，不需要移动位置。而且，对于需要移动的元素，其下一个位置也容易通过位运算来计算，比如26mod16为1010(10)，26mod32为11010(26)，只需要在旧的哈希值前面补1即可。
```

接下来，考虑如何设计一个HashMap，和HashSet类似，只需要将存储的只由key改为一个key-value键值对即可：

```java
class MyHashMap {
    private class Pair {
        private int key;
        private int value;

        public Pair(int key, int value) {
            this.key = key;
            this.value = value;
        }

        public int getKey() {
            return key;
        }

        public int getValue() {
            return value;
        }

        public void setValue(int value) {
            this.value = value;
        }
    }

    private static final int BASE = 769;
    private LinkedList<Pair>[] data;

    /**
     * 初始化
     */
    public MyHashMap() {
        data = new LinkedList[BASE];
        for (int i = 0; i < BASE; ++i) {
            data[i] = new LinkedList<>();
        }
    }
    
    public void put(int key, int value) {
        int h = hash(key);
        for (Pair pair : data[h]) {
            if (pair.getKey() == key) {
                pair.setValue(value);
                return;
            }
        }
        data[h].offerLast(new Pair(key, value));
    }

    /**
     * 找到则返回value，否则返回-1
     */
    public int get(int key) {
        int h = hash(key);
        for (Pair pair : data[h]) {
            if (pair.getKey() == key) {
                return pair.getValue();
            }
        }
        return -1;
    }
    
    public void remove(int key) {
        int h = hash(key);
        for (Pair pair : data[h]) {
            if (pair.getKey() == key) {
                data[h].remove(pair);
                return;
            }
        }
    }

    private int hash(int key) {
        return key % BASE;
    }
}
```

- 时间复杂度：$O(\frac{n}{b})$。其中 $n$ 为哈希表中的元素数量，$b$ 为链表的数量。假设哈希值是均匀分布的，则每个链表大概长度为 $\frac{n}{b}$ 
- 空间复杂度：$O(n+b)$

参考：
1. [leetcode题解：HashSet](https://leetcode.cn/problems/design-hashset/solutions/)
2. [leetcode题解：HashMap](https://leetcode.cn/problems/design-hashmap/solutions/)

### LRU缓存设计

**题目：**

请你设计并实现一个满足 LRU (Least Recently Used 最近最少使用)缓存约束的数据结构。

实现 LRUCache 类：
- LRUCache(int capacity) 以正整数作为容量 capacity 初始化 LRU 缓存；
- int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1；
- void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该逐出 最久未使用的关键字。

注意：函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。

```
示例

输入：
["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"]
[[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]

输出：
[null, null, null, 1, null, -1, null, -1, 3, 4]

解释：
LRUCache lRUCache = new LRUCache(2);
lRUCache.put(1, 1); // 缓存是 {1=1}
lRUCache.put(2, 2); // 缓存是 {1=1, 2=2}
lRUCache.get(1);    // 返回 1
lRUCache.put(3, 3); // 该操作会使得关键字 2 作废，缓存是 {1=1, 3=3}
lRUCache.get(2);    // 返回 -1 (未找到)
lRUCache.put(4, 4); // 该操作会使得关键字 1 作废，缓存是 {4=4, 3=3}
lRUCache.get(1);    // 返回 -1 (未找到)
lRUCache.get(3);    // 返回 3
lRUCache.get(4);    // 返回 4
```

**思路与代码：**

LRU 缓存机制可以通过哈希表辅以双向链表实现，我们用一个哈希表和一个双向链表维护所有在缓存中的键值对。
- 双向链表：按照被使用的顺序存储了这些键值对，靠近头部的键值对是最近使用的，而靠近尾部的键值对是最久未使用的。
- 哈希表：即为普通的哈希映射（HashMap），通过缓存数据的键映射到其在双向链表中的位置。

这样一来，我们首先使用哈希表进行定位，找出缓存项在双向链表中的位置，随后将其移动到双向链表的头部，即可在 O(1) 的时间内完成 get 或者 put 操作。具体的方法如下：

1）对于 get 操作，首先判断 key 是否存在：
- 如果 key 不存在，则返回 −1；
- 如果 key 存在，则 key 对应的节点是最近被使用的节点。通过哈希表定位到该节点在双向链表中的位置，并将其移动到双向链表的头部，最后返回该节点的值。

2）对于 put 操作，首先判断 key 是否存在：
- 如果 key 不存在，使用 key 和 value 创建一个新的节点，在双向链表的头部添加该节点，并将 key 和该节点添加进哈希表中。然后判断双向链表的节点数是否超出容量，如果超出容量，则删除双向链表的尾部节点，并删除哈希表中对应的项；
- 如果 key 存在，则与 get 操作类似，先通过哈希表定位，再将对应的节点的值更新为 value，并将该节点移到双向链表的头部。

上述各项操作中，访问哈希表的时间复杂度为 O(1)，在双向链表的头部添加节点、在双向链表的尾部删除节点的复杂度也为 O(1)。而将一个节点移到双向链表的头部，可以分成「删除该节点」和「在双向链表的头部添加节点」两步操作，都可以在 O(1) 时间内完成。

在双向链表的实现中，使用一个伪头部（dummy head）和伪尾部（dummy tail）标记界限，这样在添加节点和删除节点的时候就不需要检查相邻的节点是否存在。

Java中的LinkedHashMap即是哈希表和链表的结合，因此可以直接通过其实现：

```java
class LRUCache extends LinkedHashMap<Integer, Integer>{
    private int capacity;
    
    public LRUCache(int capacity) {
        super(capacity, 0.75F, true);
        this.capacity = capacity;
    }

    public int get(int key) {
        return super.getOrDefault(key, -1);
    }

    public void put(int key, int value) {
        super.put(key, value);
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<Integer, Integer> eldest) {
        return size() > capacity; 
    }
}
```

如果自己实现哈希表和链表的关联，完成LRU缓存，则代码为：

```java
public class LRUCache {
    class DLinkedNode {
        int key;
        int value;
        DLinkedNode prev;
        DLinkedNode next;
        public DLinkedNode() {}
        public DLinkedNode(int _key, int _value) {key = _key; value = _value;}
    }

    private Map<Integer, DLinkedNode> cache = new HashMap<Integer, DLinkedNode>();
    private int size;
    private int capacity;
    private DLinkedNode head, tail;

    public LRUCache(int capacity) {
        this.size = 0;
        this.capacity = capacity;
        // 使用伪头部和伪尾部节点
        head = new DLinkedNode();
        tail = new DLinkedNode();
        head.next = tail;
        tail.prev = head;
    }

    public int get(int key) {
        DLinkedNode node = cache.get(key);
        if (node == null) {
            return -1;
        }
        // 如果 key 存在，先通过哈希表定位，再移到头部
        moveToHead(node);
        return node.value;
    }

    public void put(int key, int value) {
        DLinkedNode node = cache.get(key);
        if (node == null) {
            // 如果 key 不存在，创建一个新的节点
            DLinkedNode newNode = new DLinkedNode(key, value);
            // 添加进哈希表
            cache.put(key, newNode);
            // 添加至双向链表的头部
            addToHead(newNode);
            ++size;
            if (size > capacity) {
                // 如果超出容量，删除双向链表的尾部节点
                DLinkedNode tail = removeTail();
                // 删除哈希表中对应的项
                cache.remove(tail.key);
                --size;
            }
        }
        else {
            // 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部
            node.value = value;
            moveToHead(node);
        }
    }

    private void addToHead(DLinkedNode node) {
        node.prev = head;
        node.next = head.next;
        head.next.prev = node;
        head.next = node;
    }

    private void removeNode(DLinkedNode node) {
        node.prev.next = node.next;
        node.next.prev = node.prev;
    }

    private void moveToHead(DLinkedNode node) {
        removeNode(node);
        addToHead(node);
    }

    private DLinkedNode removeTail() {
        DLinkedNode res = tail.prev;
        removeNode(res);
        return res;
    }
}
```

- 时间复杂度：对于 put 和 get 都是 $O(1)$
- 空间复杂度：$O(\text{capacity})$，因为哈希表和双向链表最多存储 $\text{capacity} + 1$ 个元素

参考：
- [leetcode题解：LRU](https://leetcode.cn/problems/lru-cache/solutions/259678/lruhuan-cun-ji-zhi-by-leetcode-solution/)

### LFU缓存设计

**题目：**

请你为 LFU(Least Frequently Used 最不经常使用)缓存算法设计并实现数据结构。

实现 LFUCache 类：
- LFUCache(int capacity) 用数据结构的容量 capacity 初始化对象；
- int get(int key) 如果键 key 存在于缓存中，则获取键的值，否则返回 -1；
- void put(int key, int value) 如果键 key 已存在，则变更其值；如果键不存在，请插入键值对。当缓存达到其容量 capacity 时，则应该在插入新项之前，移除最不经常使用的项。在此问题中，当存在平局（即两个或更多个键具有相同使用频率）时，应该去除最久未使用的键。

为了确定最不常使用的键，可以为缓存中的每个键维护一个 使用计数器 。使用计数最小的键是最久未使用的键。

当一个键首次插入到缓存中时，它的使用计数器被设置为 1 (由于 put 操作)。对缓存中的键执行 get 或 put 操作，使用计数器的值将会递增。

函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。

```
示例

输入：
["LFUCache", "put", "put", "get", "put", "get", "get", "put", "get", "get", "get"]
[[2], [1, 1], [2, 2], [1], [3, 3], [2], [3], [4, 4], [1], [3], [4]]

输出：
[null, null, null, 1, null, -1, 3, null, -1, 3, 4]

解释：
// cnt(x) = 键 x 的使用计数
// cache=[] 将显示最后一次使用的顺序（最左边的元素是最近的）
LFUCache lfu = new LFUCache(2);
lfu.put(1, 1);   // cache=[1,_], cnt(1)=1
lfu.put(2, 2);   // cache=[2,1], cnt(2)=1, cnt(1)=1
lfu.get(1);      // 返回 1
                 // cache=[1,2], cnt(2)=1, cnt(1)=2
lfu.put(3, 3);   // 去除键 2 ，因为 cnt(2)=1 ，使用计数最小
                 // cache=[3,1], cnt(3)=1, cnt(1)=2
lfu.get(2);      // 返回 -1（未找到）
lfu.get(3);      // 返回 3
                 // cache=[3,1], cnt(3)=2, cnt(1)=2
lfu.put(4, 4);   // 去除键 1 ，1 和 3 的 cnt 相同，但 1 最久未使用
                 // cache=[4,3], cnt(4)=1, cnt(3)=2
lfu.get(1);      // 返回 -1（未找到）
lfu.get(3);      // 返回 3
                 // cache=[3,4], cnt(4)=1, cnt(3)=3
lfu.get(4);      // 返回 4
                 // cache=[3,4], cnt(4)=2, cnt(3)=3
```

**思路与代码：**

**方法一：哈希表 + 平衡二叉树**

由于主流语言中都有内置平衡二叉树，因此利用其进行自动排序从而实现 LFU 较为方便，但应注意其时间复杂度是 $O(log(n))$ 并非 $O(1)$ 。

首先我们定义缓存的数据结构，java中可以通过实现Comparable类来自定义比较函数：

```java
class Node implements Comparable<Node> {
    // cnt 表示缓存使用的频率，time 表示缓存的使用时间，key 和 value 表示缓存的键值
    int cnt, time, key, value;

    Node(int cnt, int time, int key, int value) {
        this.cnt = cnt;
        this.time = time;
        this.key = key;
        this.value = value;
    }

    public boolean equals(Object anObject) {
        if (this == anObject) {
            return true;
        }
        if (anObject instanceof Node) {
            Node rhs = (Node) anObject;
            return this.cnt == rhs.cnt && this.time == rhs.time;
        }
        return false;
    }

    // 比较函数：将cnt（使用频率）作为第一关键字，time（最近一次使用的时间）作为第二关键字
    public int compareTo(Node rhs) {
        return cnt == rhs.cnt ? time - rhs.time : cnt - rhs.cnt;
    }

    public int hashCode() {
        return cnt * 1000000007 + time;
    }
}
```

我们用哈希表 keyTable 以键 key 为索引存储缓存 Node，建立一个平衡二叉树 treeSet 来保持缓存根据 (cnt，time) 双关键字排序。
在 Java 中，我们可以使用 TreeSet 类，其背后的实现是红黑树（一种特化的AVL树即平衡二叉树）：

1）对于 get(key) 操作，我们只要查看一下哈希表 keyTable 是否有 key 这个键即可，有的话需要同时更新哈希表和集合中该缓存的使用频率以及使用时间，否则返回 -1。

2）对于 put(key, value) 操作，首先需要查看 keyTable 中是否已有对应的键值。如果有的话操作基本等同于 get(key)，不同的是需要更新缓存的 value 值。如果没有的话相当于是新插入一个缓存，这时候需要先查看是否达到缓存容量 capacity，如果达到了的话，需要删除最近最少使用的缓存，即平衡二叉树中最左边的结点，同时删除 keyTable 中对应的索引，最后向 keyTable 和 treeSet 插入新的缓存信息即可。

```java
class LFUCache {
    // 缓存容量，时间戳
    int capacity, time;
    Map<Integer, Node> keyTable;
    TreeSet<Node> treeSet;

    public LFUCache(int capacity) {
        this.capacity = capacity;
        this.time = 0;
        keyTable = new HashMap<>();
        treeSet = new TreeSet<>();
    }

    public int get(int key) {
        if (capacity == 0) {
            return -1;
        }
        // 如果哈希表中没有键 key，返回 -1
        if (!keyTable.containsKey(key)) {
            return -1;
        }
        // 从哈希表中得到旧的缓存
        Node cache = keyTable.get(key);
        // 从平衡二叉树中删除旧的缓存
        treeSet.remove(cache);
        // 将旧缓存更新
        cache.cnt += 1;
        cache.time = ++time;
        // 将新缓存重新放入哈希表和平衡二叉树中
        treeSet.add(cache);
        keyTable.put(key, cache);
        return cache.value;
    }

    public void put(int key, int value) {
        if (capacity == 0) {
            return;
        }
        if (!keyTable.containsKey(key)) {
            // 如果到达缓存容量上限
            if (keyTable.size() == capacity) {
                // 从哈希表和平衡二叉树中删除最近最少使用的缓存
                keyTable.remove(treeSet.first().key);
                treeSet.remove(treeSet.first());
            }
            // 创建新的缓存
            Node cache = new Node(1, ++time, key, value);
            // 将新缓存放入哈希表和平衡二叉树中
            keyTable.put(key, cache);
            treeSet.add(cache);
        } else {
            // 这里和 get() 函数类似
            Node cache = keyTable.get(key);
            treeSet.remove(cache);
            cache.cnt += 1;
            cache.time = ++time;
            cache.value = value;
            treeSet.add(cache);
            keyTable.put(key, cache);
        }
    }
}
```

- 时间复杂度：get 时间复杂度 $O(\log n)$，put 时间复杂度 $O(\log n)$，操作的时间复杂度瓶颈在于平衡二叉树的插入删除均需要 $O(\log n)$ 的时间。
- 空间复杂度：$O(\textit{capacity})$，其中 capacity 为 LFU 的缓存容量。哈希表和平衡二叉树不会存放超过缓存容量的键值对。

**方法二：双哈希表**

我们定义两个哈希表，第一个 freqTable 以频率 freq 为索引，每个索引存放一个双向链表，这个链表里存放所有使用频率为 freq 的缓存，缓存里存放三个信息，分别为键 key，值 value，以及使用频率 freq。第二个 keyTable 以键值 key 为索引，每个索引存放对应缓存在 freqTable 中链表里的内存地址，这样我们就能利用两个哈希表来使得两个操作的时间复杂度均为 O(1)。同时需要记录一个当前缓存最少使用的频率 minFreq，这是为了删除操作服务的。

1）对于 get(key) 操作，我们能通过索引 key 在 keyTable 中找到缓存在 freqTable 中的链表的内存地址，如果不存在直接返回 -1，否则我们能获取到对应缓存的相关信息，这样我们就能知道缓存的键值还有使用频率，直接返回 key 对应的值即可。

但是我们注意到 get 操作后这个缓存的使用频率加一了，所以我们需要更新缓存在哈希表 freqTable 中的位置。已知这个缓存的键 key，值 value，以及使用频率 freq，那么该缓存应该存放到 freqTable 中 freq + 1 索引下的链表中。所以我们在当前链表中 O(1) 删除该缓存对应的节点，根据情况更新 minFreq 值，然后将其 O(1) 插入到 freq + 1 索引下的链表头完成更新。这其中的操作复杂度均为 O(1)。你可能会疑惑更新的时候为什么是插入到链表头，这其实是为了保证缓存在当前链表中从链表头到链表尾的插入时间是有序的，为下面的删除操作服务。

2）对于 put(key, value) 操作，我们先通过索引 key在 keyTable 中查看是否有对应的缓存，如果有的话，其实操作等价于 get(key) 操作，唯一的区别就是我们需要将当前的缓存里的值更新为 value。如果没有的话，相当于是新加入的缓存，如果缓存已经到达容量，需要先删除最近最少使用的缓存，再进行插入。

先考虑插入，由于是新插入的，所以缓存的使用频率一定是 1，所以我们将缓存的信息插入到 freqTable 中 1 索引下的列表头即可，同时更新 keyTable\[key\] 的信息，以及更新 minFreq = 1。

那么剩下的就是删除操作了，由于我们实时维护了 minFreq，所以我们能够知道 freqTable 里目前最少使用频率的索引，同时因为我们保证了链表中从链表头到链表尾的插入时间是有序的，所以 freqTable\[minFreq\] 的链表中链表尾的节点即为使用频率最小且插入时间最早的节点，我们删除它同时根据情况更新 minFreq ，整个时间复杂度均为 O(1) 。

```java
class LFUCache {
    int minfreq, capacity;
    Map<Integer, Node> keyTable;
    Map<Integer, DoublyLinkedList> freqTable;

    public LFUCache(int capacity) {
        this.minfreq = 0;
        this.capacity = capacity;
        keyTable = new HashMap<Integer, Node>();
        freqTable = new HashMap<Integer, DoublyLinkedList>();
    }
    
    public int get(int key) {
        if (capacity == 0) {
            return -1;
        }
        if (!keyTable.containsKey(key)) {
            return -1;
        }
        Node node = keyTable.get(key);
        int val = node.val, freq = node.freq;
        freqTable.get(freq).remove(node);
        // 如果当前链表为空，我们需要在哈希表中删除，且更新minFreq
        if (freqTable.get(freq).size == 0) {
            freqTable.remove(freq);
            if (minfreq == freq) {
                minfreq += 1;
            }
        }
        // 插入到 freq + 1 中
        DoublyLinkedList list = freqTable.getOrDefault(freq + 1, new DoublyLinkedList());
        list.addFirst(new Node(key, val, freq + 1));
        freqTable.put(freq + 1, list);
        keyTable.put(key, freqTable.get(freq + 1).getHead());
        return val;
    }
    
    public void put(int key, int value) {
        if (capacity == 0) {
            return;
        }
        if (!keyTable.containsKey(key)) {
            // 缓存已满，需要进行删除操作
            if (keyTable.size() == capacity) {
                // 通过 minFreq 拿到 freqTable[minFreq] 链表的末尾节点
                Node node = freqTable.get(minfreq).getTail();
                keyTable.remove(node.key);
                freqTable.get(minfreq).remove(node);
                if (freqTable.get(minfreq).size == 0) {
                    freqTable.remove(minfreq);
                }
            }
            DoublyLinkedList list = freqTable.getOrDefault(1, new DoublyLinkedList());
            list.addFirst(new Node(key, value, 1));
            freqTable.put(1, list);
            keyTable.put(key, freqTable.get(1).getHead());
            minfreq = 1;
        } else {
            // 与 get 操作基本一致，除了需要更新缓存的值
            Node node = keyTable.get(key);
            int freq = node.freq;
            freqTable.get(freq).remove(node);
            if (freqTable.get(freq).size == 0) {
                freqTable.remove(freq);
                if (minfreq == freq) {
                    minfreq += 1;
                }
            }
            DoublyLinkedList list = freqTable.getOrDefault(freq + 1, new DoublyLinkedList());
            list.addFirst(new Node(key, value, freq + 1));
            freqTable.put(freq + 1, list);
            keyTable.put(key, freqTable.get(freq + 1).getHead());
        }
    }
}

class Node {
    int key, val, freq;
    Node prev, next;

    Node() {
        this(-1, -1, 0);
    }

    Node(int key, int val, int freq) {
        this.key = key;
        this.val = val;
        this.freq = freq;
    }
}

class DoublyLinkedList {
    Node dummyHead, dummyTail;
    int size;

    DoublyLinkedList() {
        dummyHead = new Node();
        dummyTail = new Node();
        dummyHead.next = dummyTail;
        dummyTail.prev = dummyHead;
        size = 0;
    }

    public void addFirst(Node node) {
        Node prevHead = dummyHead.next;
        node.prev = dummyHead;
        dummyHead.next = node;
        node.next = prevHead;
        prevHead.prev = node;
        size++;
    }

    public void remove(Node node) {
        Node prev = node.prev, next = node.next;
        prev.next = next;
        next.prev = prev;
        size--;
    }

    public Node getHead() {
        return dummyHead.next;
    }

    public Node getTail() {
        return dummyTail.prev;
    }
}
```

- 时间复杂度：get 时间复杂度 $O(1)$ ，put 时间复杂度 $O(1)$ 。由于两个操作从头至尾都只利用了哈希表的插入删除还有链表的插入删除，且它们的时间复杂度均为 $O(1)$ ，所以保证了两个操作的时间复杂度均为 $O(1)$ 。
- 空间复杂度：$O(\textit{capacity})$ ，其中 capacity 为 LFU 的缓存容量。哈希表中不会存放超过缓存容量的键值对。

参考：
- [leetcode题解：LFU](https://leetcode.cn/problems/lfu-cache/solutions/186348/lfuhuan-cun-by-leetcode-solution/)

## 练习题目

**题目**
- LeetCode 36. Valid Sudoku 有效的数独
- LeetCode 49. Group Anagrams 字母异位词分组
- LeetCode 169. Majority Element 多数元素
- LeetCode 202. Happy Number 快乐数
- LeetCode 205. Isomorphic Strings 同构字符串
- LeetCode 287. Find the Duplicate Number 寻找重复数
- LeetCode 349. Intersection of Two Arrays 两个数组的交集
- LeetCode 350. Intersection of Two Arrays II 两个数组的交集 II
- LeetCode 387. First Unique Character in a String 字符串中的第一个唯一字符
- LeetCode 454. 4Sum II 四数相加 II
- LeetCode 705. Design HashSet 设计哈希集合
- LeetCode 706. Design HashMap 设计哈希映射
- （困难）LeetCode 146. LRU Cache LRU 缓存
- （困难）LeetCode 380. Insert Delete GetRandom O(1) O(1) 时间插入、删除和获取随机元素
- （困难）LeetCode 460. LFU Cache LFU 缓存

**思路**
- LeetCode 36. 
> 方法一：分别按行、按列、按九宫遍历
> 
> 复杂度：1（遍历次数为常数）
> 
> 方法二：官方解答中，也可以把三次遍历转为一次遍历，并同时记录三种条件下的重复情况
> 
> 复杂度：1（遍历次数为常数）
> 
- LeetCode 49. 
> 生成每个字符串的排序后字符串，通过hash表做映射
> 
> 复杂度：n\*m\*log(m)
- LeetCode 169. 
> 通过map统计每个数字出现个数，然后返回个数最大的数字
> 
> 复杂度：n
> 
- LeetCode 202. 
> 方法一：使用HashSet
> 
> 复杂度：log(n)
> 
> 方法二：官方解答还提出可以使用快慢指针来实现，等价于找到链表是否有环
> 
> 复杂度：log(n)
> 
- LeetCode 205. 
> 保存两字符串的对应字符的映射关系，注意要保留相互两份映射
> 
> 复杂度：n
> 
- LeetCode 287. 
> 方法一：使用HashSet
> 
> 复杂度：时间n、空间n
> 
> 方法二：官方解答中提到了一种时间n、空间1的方法，双指针法。
> 
> 首先将数组构造成链表（必然有环）index->nums[index]
> 
> 0 1 2 3 4
> 
> 1 3 4 2 2
> 
> 链表为：0->1->3->2->4(->2成环)
> 
> 简单证明为什么一定成环，首先0作为起点，只会指向别的节点，不会有节点指向0，这样（除去0）index就有n个，而被指向的节点共有n+1个，所以必然有一个节点至少被从两个位置指向（包括自指向）
> 
> 注意：不一定只有一个环，但从0出发的一定能找到有且一个环，如下例子：
> 
> 0 1 2 3 4
> 
> 1 2 2 4 3
> 
> 链表为：0->1->2(->2自成环)
> 
> 3->4(->3成第二个环)
> 
> 这样构造出从0出发的一定有一个环的链表，且环入口就是重复元素，就可以使用快慢指针来找到了，而且这个链表并不一定要真正的构造出来，index和nums[index]的关系已经足够。
> 
> 复杂度：时间n、空间1
> 
- LeetCode 349. 
> 使用HashSet
> 
> 复杂度：n
> 
- LeetCode 350. 
> 使用HashMap，计数
> 
> 复杂度：n
> 
- LeetCode 387. 
> 使用map计数，还可以使用Ascii码数组计数，速度更快
> 
> 复杂度：n
> 
- LeetCode 454. 
> 分别计算数组1、2和数组3、4的所有和的统计结果map，然后遍历和为0的计数。另外，如果数组重复值多的话，还可以继续优化，先统计数字出现个数，再生成统计map
> 
> 复杂度：n^2
> 
- LeetCode 705. 
> 使用一个数组存数据，数组元素是一个链表表头，该链表下所有key的hash值相等。
> 
> 另外，这里只是给出一个最简单的hashSet实现，如果要进行优化，可以从下面几点考虑：
> 
> 1）hash函数，可以采用更优的散列函数。
> 
> 2）链表改为树，参考Java内置HashMap的实现。
> 
> 3）扩容机制，当元素个数过多时，可以对其进行扩容，降低hash冲突概率。
> 
> 复杂度：>1
> 
- LeetCode 706. 
> 与705相似
> 
> 复杂度：>1
> 
- （困难）LeetCode 146. 
> 方法一：通过双向链表（目的是保存先后顺序）表示LRU，但查询复杂度为n，所以增加一个辅助hash表，使得查询复杂度降为1
> 
> 复杂度：1
> 
> 方法二：还可以借助java提供的LinkedHashMap来实现，它本身就是通过list+hash结合实现的
> 
> 复杂度：1
> 
- （困难）LeetCode 380. 
> 使用一个HashMap，一个ArrayList
> 
> 复杂度：1
> 
- （困难）LeetCode 460. 
> map-list-map方案：
> 
> 首先建立一个hashmap，key是访问次数，value是一个linkedList，list内所有节点的访问次数是一样的，并按访问时间排序。
> 
> 然后再建立一个hashmap，key是输入数据的key，value是上述list的节点，为了方便定位某个具体key-value数据。
> 
> 最后再维护一个当前最小访问次数的变量，用户快速找到需要剔除的元素。
> 
> 复杂度：1
> 
